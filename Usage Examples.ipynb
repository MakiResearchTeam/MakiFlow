{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MakiFlow usage examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains basic guidelines of using MakiFlow. MakiFlow is not a serious framework like PyTorch or TensorFlow, this is an instrument I built in order to improve quality and speed of my researches in the field of Neural Networks, especially CNNs. If you found this library useful and have some thoughs how to improve it or what to fix I'd like to listen to you. My email: igor.kilbas@mail.ru."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing MakiFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as I don't know how to create high quality libraries, you're gonna have some pain. Here is the way I import MakiFlow on my computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/student401/MakiFlow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating CNN based on MakiFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have an access to MakiFlow and can import stuff related to it.\n",
    "In order to create CNN you need to defined layers order first. Here is what I mean by that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student401/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from makiflow.layers import ConvLayer, DenseLayer, MaxPoolLayer, FlattenLayer\n",
    "\n",
    "layers = [\n",
    "        ConvLayer(kw=3, kh=3, in_f=3, out_f=64, name='input_layer'),\n",
    "        ConvLayer(kw=3, kh=3, in_f=64, out_f=64, name=2),\n",
    "        MaxPoolLayer(),\n",
    "    \n",
    "        ConvLayer(kw=3, kh=3, in_f=64, out_f=128, name=4),\n",
    "        ConvLayer(kw=3, kh=3, in_f=128, out_f=128, name=5),\n",
    "        MaxPoolLayer(),\n",
    "    \n",
    "        ConvLayer(kw=3, kh=3, in_f=128, out_f=256, name=6),\n",
    "        ConvLayer(kw=3, kh=3, in_f=256, out_f=256, name=7),\n",
    "        MaxPoolLayer(),\n",
    "    \n",
    "        ConvLayer(kw=3, kh=3, in_f=256, out_f=512, name=8),\n",
    "        ConvLayer(kw=3, kh=3, in_f=512, out_f=512, name=9),\n",
    "        ConvLayer(kw=3, kh=3, in_f=512, out_f=512, name=10),\n",
    "        MaxPoolLayer(),\n",
    "    \n",
    "        FlattenLayer(),\n",
    "        DenseLayer(input_shape=2048, output_shape=1024, name=12),\n",
    "        DenseLayer(input_shape=1024, output_shape=1024, name=13),\n",
    "        DenseLayer(input_shape=1024, output_shape=10, activation=None, name='out_put_layer')\n",
    "    # The last layer always is gonna have no activation function! Just always pass None into 'activation' argument!\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have built basic VGG model. As you might have noticed, you have to directly pass the number of input feature maps and output feature maps, so be careful with that. Tip: number of the input feature maps in the next layer equals number of the feature maps in the previous layer. Anyway, TensorFlow will get you know if something is wrong.\n",
    "\n",
    "To create CNN, we need ConvModel class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makiflow import ConvModel\n",
    "\n",
    "model = ConvModel(layers=layers, input_shape=[64, 32, 32, 3], output_shape=[64, 10], name='My_MakiFlow_little_VGG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! You've just created your first CNN based on MakiFlow! But we still have some stuff to do.\n",
    "\n",
    "First, ConvModel requires TensorFlow Session in order to work. You can treat ConvModel as a car and Session as an engine. Let's add an engine to our car:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "session = tf.Session()\n",
    "model.set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the model. Let's train it. We'll use cifar10 dataset for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(Xtrain, Ytrain), (Xtest, Ytest) = cifar10.load_data()\n",
    "    \n",
    "Xtrain = Xtrain.astype(np.float32)\n",
    "Xtest = Xtest.astype(np.float32)\n",
    "\n",
    "Xtrain /= 255\n",
    "Xtest /= 255\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "Ytrain = keras.utils.to_categorical(Ytrain, 10)\n",
    "Ytest = keras.utils.to_categorical(Ytest, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second step is to define our training parameters:\n",
    "learning_rate;\n",
    "optimizer - ConvModel uses TensorFlow optimizers in order to train the model;\n",
    "epochs;\n",
    "\n",
    "We will use RMSProp for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "lr = 1e-5*128\n",
    "epsilon = 1e-6\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=lr, epsilon=epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train the model we can call two methods:\n",
    "verbose_fit - tests the model on train data and test data;\n",
    "pure_fit - tests the model only on test data, it works much faster than verbose_fit.\n",
    "\n",
    "We will use pure fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 781/781 [00:13<00:00, 58.38it/s]\n",
      "  0%|          | 0/781 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train accuracy: 0.21233446193512973 Train cost: 2.0322607538318254 Test accuracy 0.25739999999999996 Test cost 1.9103252704326923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 781/781 [00:12<00:00, 61.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train accuracy: 0.4534793300054287 Train cost: 1.4788230974867071 Test accuracy 0.4505 Test cost 1.4869333902994792\n"
     ]
    }
   ],
   "source": [
    "info = model.pure_fit(Xtrain, Ytrain, Xtest, Ytest, optimizer=optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pure_fit method returns dictionary with tests' info on each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train costs': [2.0322607538318254, 1.4788230974867071],\n",
       " 'train errors': [0.7876655380648703, 0.5465206699945713],\n",
       " 'test costs': [1.9103252704326923, 1.4869333902994792],\n",
       " 'test errors': [0.7426, 0.5495]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the model, simply call the method evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:01<00:00, 147.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4505 Cost: 1.4869339580719287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions using MakiFlow model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make predictions, we use predict method. \n",
    "This method requires tensor of shape (number_of_samples, dim, dim, channels).\n",
    "It always returns numpy array with probabilities of belonging this particular sample(or samples) to each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01108474, 0.00861162, 0.12099435, 0.36020404, 0.06199497,\n",
       "        0.27742323, 0.10490333, 0.03577648, 0.01214113, 0.00686607]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(Xtest[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving/loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have trained model, we would like to save it's weights and architecture. ConvModel class has methods written for this purpose: to_json(), save_weights()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in your mind that you have to insert @FULL PATH of the directory you want to save weights in + name of the weights file@. Weights saving system uses TensorFlow's checkpoint file, so be careful and don't forget to add '.ckpt' at the end of the name of the weights file. Here is the way I do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to /home/student401/temp/my_model_weights.ckpt\n"
     ]
    }
   ],
   "source": [
    "model.save_weights('/home/student401/temp/my_model_weights.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As might have noticed, model's architecture is gonna be stored in json file. In order to save the architecture, you need to pass in @PATH to directory you want to save the architecture in + name of the json file@. In this case it's not necessary to insert FULL PATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's architecture is saved to /home/student401/temp/my_model_architecture.json.\n"
     ]
    }
   ],
   "source": [
    "model.to_json('/home/student401/temp/my_model_architecture.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating model from existing architecure file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always good to have pretrained models so that you can use their weights or fine-tune them at any time. Let's create new model with the architecture we defined erlier.\n",
    "In order to do this, we need to import Builder class that creates ConvModel from json file. Builder class has one main method: convmodel_from_json(). It takes path to json file with the architecture we need and returns ConvModel object with predefined architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makiflow.save_recover.builder import Builder\n",
    "\n",
    "new_model = Builder.convmodel_from_json('/home/student401/temp/my_model_architecture.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to load weights, simply call load_weights() method in ConvModel object. This method takes path to the checkpoint file and loads weights. You also must initialize the model with some session, otherwise it won't be able to load weights.\n",
    "#### IMPORTANT!\n",
    "CNN (ConvModel) must have the same architecture like the model these weights were taken from, all the layers' names must be the same, otherwise it may cause errors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/student401/temp/my_model_weights.ckpt\n",
      "Model restored\n"
     ]
    }
   ],
   "source": [
    "new_model.set_session(session)\n",
    "new_model.load_weights('/home/student401/temp/my_model_weights.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the model to make sure if it's the same as previous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [00:01<00:00, 142.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4505 Cost: 1.4869339580719287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_model.evaluate(Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
